\documentclass{bioinfo}
\copyrightyear{2007}
\pubyear{2007}

\begin{document}
\firstpage{1}

\title[Open-source peptide identification algorithm]{Open-source
peptide identification algorithm}
\author[Park \textit{et~al}]{Christopher Park$^{\rm a}$, Aaron Klammer$^{\rm a}$,
Lukas K\"{a}ll$^{\rm a}$, 
William S. Noble\,$^{\rm a,b,}$\footnote{To whom correspondence should be addressed}}
\address{
$^{\rm a}$Department of Computer Science and Engineering,
$^{\rm b}$Department of Genome Sciences, University of Washington,
  Seattle, WA, USA
}
\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\maketitle

\begin{abstract}
\section{Motivation:}

\section{Results:}

\section{Availability:}
\href{http://noble.gs.washington.edu/proj/crux}{http://noble.gs.washington.edu/proj/crux}
\section{Contact:} \href{noble@gs.washington.edu}{noble@gs.washington.edu}
\end{abstract}

\section{Introduction}

% Paragraph - Motivation   - Define the peptide identification problem
Tandem mass spectrometry is the method of choice for many protein
identification studies.  However, this technology currently suffers
from an analysis bottleneck, with a need for more efficient and more
accurate methods of mapping from the observed fragmentation spectra to
the corresponding peptides.

% Paragraph - Related Work - SEQUEST, Tandem as open source?
The most widely used methods for peptide identification, such as
SEQUEST \cite{eng:approach}, MASCOT \cite{}, Tandem \cite{} and
Inspect \cite{}, exploit a database of known protein sequences.  For
each observed spectrum, these methods search the database for the
peptide whose theoretical spectrum best matches the observed spectrum.
The resulting peptide-spectrum matches (PSMs) can be ranked using a
pre-defined score function, or by using machine learning methods such
as linear discriminant analysis \cite{}, support vector machines
\cite{} or decision trees \cite{}.

In this work, we describe a computational tool called Crux that solves
the peptide identification problem efficiently and accurately.  As
illustrated in Figure~\ref{figure:crux}, Crux incorporates a rapid
peptide lookup scheme, a static scoring system for relative ranking of
peptides with respect to each spectrum, a null model based on a decoy
database of shuffled peptides generated on the fly, and a dynamically
trained support vector machine for ranking the complete collection of
PSMs.  Relative to the current state of the art, Crux makes three
primary contributions:

\begin{itemize}

\item {\bf Efficient retrieval of candidate peptides.}  Given a
  spectrum with a specified precursor mass-to-charge ratio (m/z), Crux
  uses a precomputed peptide database to retrieve efficiently all
  peptides whose m/z lies within a user-specified window around the
  target m/z (called {\em candidate peptides}).  The database is
  sorted by peptide mass and is stored on disk, with mass indices
  stored in memory.  We show that, relative to SEQUEST's strategy of
  reading the protein sequence database from disk for each new
  spectrum, the indexed database decreases search time by X\% on
  average.

\item {\bf On-the-fly generation of decoy peptides.}  In evaluating
  the statistical significance of a PSM, mass spectrometrists
  frequently employ a {\em decoy database} comprised of protein
  sequences that have been reversed, shuffled or generated from a
  Markov chain derived from the original {\em target database}.
  The number of matches to the decoy database yields an estimate of
  the false discovery rate associated with a collection of target
  PSMs.  Crux uses this strategy, but generates decoy peptides on the
  fly by shuffling the non-terminal amino acids 

In algorithms that are used to search tandem MS spectra data against a
sequence database, a major bottleneck is the identification of
candidate peptides within a given mass window. Because scoring
functions are expensive procedure, all database algorithms produce a
smaller list of candidate peptides to be analyzed. However, generating
candidate peptides separately for each search can be wasteful for
large proteomes, because many times there are overlapping mass windows
of peptides. Therefore, by using a precomputed database, database
scoring algorithms can avoid re-generating peptides for each
search. Thus, resulting in dramatic reduction in runtime for large
proteome searches. TurboSEQUEST, a extension of SEQUEST, utilizes a
precomputed peptide database, however the application is not publicly
available.

% Paragraph - Related Work - Target decoy searches
% Paragraph - Related Work - Percolator
% Paragraph - Contribution - Four points of improvement
%  - Indexing
%  - "Open source" implementation of scoring functions
%  - Null peptide generation
%  - Percolator post processing
% Paragraph - Contribution - Brief results description


\section{Approach}

\subsection{Indexing}
When given a protein fasta file as input, we generate an index of all
of its peptides on disk. The database created on disk is then used
during runtime as an input to generate candidate peptides within the
mass window of the query spectrum m/z. The main difficulties in
creating a database is first, dealing with memory shortage problems
caused by the large number of peptides,second, reducing the disk size
of the database. The key strategy to resolve the memory shortage
problem was to temporary store peptides in separate bins(file handles)
divided by mass interval, then sort each bin individually. By
partitioning the peptides into different mass bins, the total amount
of peptides needed to be sorted at one instance reduces dramatically
compared to sorting all the peptides together, thus reducing the
amount of memory needed to store the peptides. Reducing the disk size
of the database was accomplished by only storing information that was
not already present in the fasta file. For instance, instead of
storing the sequence of each individual peptide, only the protein
index, the start index and the peptide length are stored, thus when
needed, the program can quickly retrieve the sequence from the
original fasta file.

\subsection{Scoring}
We re-implemented the two scoring functions Sp, Xcorr used in SEQUEST
for Crux.  First, the preliminary scoring function Sp is used to
extract the top 500 candidate peptides. To avoid erroneous scores by
noise, the spectrum is preprocessed by square rooting and smoothing
all peak intensities before extracting the top 200 abundant peaks to
be scored for Sp.  Second, The main scoring function Xcorr is used for
the final cross-correlation analysis. A similar preprocessing step
used in Sp is applied in Xcorr. For further detail on scoring function
and preprocessing steps refer to source code.

\subsection{Null peptide generation}
\subsection{Percolator}
\subsection{Parallelization}

\begin{methods}
\section{Methods}

\end{methods}

\section{Results}

\begin{figure}
  \centering
  Insert figure here
  \caption{Peptide indexing allows rapid generation of candidate peptide
  lists.}
  \label{figure:indexing}
\end{figure}

\begin{figure}
  \centering
  \begin{tabular}{c}
  Insert figure here \\
  Insert figure here \\
  \caption{Re-implementation of Sp and Xcorr scoring functions.}
  \label{figure:indexing}
  \end{tabular}
\end{figure}

\begin{figure}
  \centering
  Insert figure here
  \caption{Positives vs. q-value (a measure of false discovery rate) for
  standard database search algorithms, and our implementation.}
  \label{figure:indexing}
\end{figure}

Hardware: All experiments were performed on RedHat linux machine with
Athlon MP 2000, 2 x 1.67 GHz processor and 2GB of RAM.  First, using
Crux, we precomputed a peptide database for tryptic peptides of length
6 to 50 amino acids while allowing missed cleavage sites in the
nr-db(06/02/2007, 3,292,818 proteins). This procedure required 19hrs
and 14GB of disk space.

Second, we verified that our re-implemented SP and Xcorr scoring
functions are identical to the scores computed by SEQUEST.

Third, to test our indexing method for candidate peptide generation,
we compared its runtime to SEQUEST.  We use a modified version of
SEQUEST that only computes Sp (and not XCorr), and we compare its
running time to that of Crux.  For both methods, we performed searches
with 100 different spectra, using a mass tolerance of 3.  SEQUEST
required 3.55hrs clock time. Crux required 0.58hrs clock time, which
is roughly a six-fold speed improvement. We also tested Crux using a
smaller mass tolerance window, such as might be used with
high-resolution mass spectrometry instrumentation.  As the mass
tolerance window decreases, Crux's speed improves, because fewer
candidate peptides are retrieved from the database.  SEQUEST, by
contrast, must traverse the entire database, regardless of the mass
tolerance.  With a mass tolerance window of 0.1, SEQUEST requires
3.5hrs clock time, whereas Crux requires 0.1hrs.  This represents an
30-fold improvement.These results show that our method of using a
pre-computed peptide database outperforms SEQUEST, especially on large
proteomes or when searching with a small mass tolerance.

Finally, we test our false discovery rate for Crux using the
Percolator algorithm compared to stadndard database searching
algorithms.

\subsection*{Datasets}
We use the following publicly available tandem mass spectrometry data
sets.

\section{Discussion}
% Mention Ting Chen's contribution
Discuss this!

\section*{Funding}

\section*{Acknowledgment}

Acknowledge this!

% We thank Grant and Tobias Mann for helpful advice. Funding:
% NIH grants U01~HG003161 and R01~GM071923.


% N.B. We should make sure to mention the file-handle limit at some point.
% N.B. To use the bibliography, check out the 'refs' CVS module and add it to
% your Bibtex path.

\bibliographystyle{plainnat}
\bibliography{refs} 

\end{document}
